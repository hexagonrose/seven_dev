{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print edge_length, edge_embedding, edge_attr values and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "edge_length_list = []\n",
    "edge_embedding_list = []\n",
    "edge_attr_list = []\n",
    "for i in range(10):\n",
    "    edge_length_list.append(torch.load(f\"edge_length_{i}.pth\", map_location=torch.device('cpu')))\n",
    "    edge_embedding_list.append(torch.load(f\"edge_embedding_{i}.pth\", map_location=torch.device('cpu')))\n",
    "    edge_attr_list.append(torch.load(f\"edge_attr_{i}.pth\", map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(edge_length_list)):\n",
    "    print(torch.equal(edge_length_list[0], edge_length_list[i]))\n",
    "    print(torch.equal(edge_embedding_list[0], edge_embedding_list[i]))\n",
    "    print(torch.equal(edge_attr_list[0], edge_attr_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([818])\n",
      "torch.Size([818, 8])\n",
      "torch.Size([818, 9])\n"
     ]
    }
   ],
   "source": [
    "# filter test!!\n",
    "condition = edge_length < 4\n",
    "new_edge_length = edge_length[condition]\n",
    "new_edge_embedding = edge_embedding[condition]\n",
    "new_edge_attr = edge_attr[condition]\n",
    "print(new_edge_length.shape)\n",
    "print(new_edge_embedding.shape)\n",
    "print(new_edge_attr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive test for edge filtering for multi cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sevenn._keys as KEY\n",
    "import sevenn.util as util\n",
    "from sevenn.atom_graph_data import AtomGraphData\n",
    "from sevenn.nn.sequential import AtomGraphSequential\n",
    "from sevenn.train.dataload import unlabeled_atoms_to_graph\n",
    "from ase.io import read\n",
    "from sevenn.nn.edge_embedding import (\n",
    "    BesselBasis,\n",
    "    EdgeEmbedding,\n",
    "    PolynomialCutoff,\n",
    "    SphericalEncoding,\n",
    "    XPLORCutoff,\n",
    ")\n",
    "from sevenn._const import DEFAULT_E3_EQUIVARIANT_MODEL_CONFIG\n",
    "from sevenn.model_build import init_edge_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = read('Mg4Ta8O24.cif')\n",
    "graph_6cut = AtomGraphData.from_numpy_dict(unlabeled_atoms_to_graph(atoms, 6.0))\n",
    "graph_4cut = AtomGraphData.from_numpy_dict(unlabeled_atoms_to_graph(atoms, 4.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "torch.Size([36]) torch.Size([36])\n",
      "edge_index\n",
      "torch.Size([2, 2910]) torch.Size([2, 818])\n",
      "pos\n",
      "torch.Size([36, 3]) torch.Size([36, 3])\n",
      "node_attr\n",
      "torch.Size([36]) torch.Size([36])\n",
      "atomic_numbers\n",
      "torch.Size([36]) torch.Size([36])\n",
      "edge_vec\n",
      "torch.Size([2910, 3]) torch.Size([818, 3])\n",
      "cell_lattice_vectors\n",
      "torch.Size([3, 3]) torch.Size([3, 3])\n",
      "pbc_shift\n",
      "torch.Size([2910, 3]) torch.Size([818, 3])\n",
      "cell_volume\n",
      "torch.Size([]) torch.Size([])\n",
      "num_atoms\n",
      "torch.Size([]) torch.Size([])\n",
      "data_info\n"
     ]
    }
   ],
   "source": [
    "# there's only edge_vec and edge_index. There's no edge_length, edge_embed, and edge_attr. -> we should build Edgeembedding layer!\n",
    "for key, value in graph_6cut.items():\n",
    "    print(key)\n",
    "    try:\n",
    "        print(graph_6cut[key].shape, graph_4cut[key].shape)\n",
    "    except:\n",
    "        pass\n",
    "    # print('---------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'irreps_manual': False, 'channel': 32, 'lmax': 1, 'lmax_edge': -1, 'lmax_node': -1, 'is_parity': True, 'radial_basis': {'radial_basis_name': 'bessel'}, 'cutoff_function': {'cutoff_function_name': 'poly_cut'}, 'act_radial': 'silu', 'cutoff': 6, 'weight_nn_hidden_neurons': [64, 64], 'num_convolution_layer': 3, 'act_scalar': {'e': 'silu', 'o': 'tanh'}, 'act_gate': {'e': 'silu', 'o': 'tanh'}, 'conv_denominator': 'avg_num_neigh', 'train_denominator': False, 'train_shift_scale': False, 'use_bias_in_linear': False, 'readout_as_fcn': False, 'readout_fcn_hidden_neurons': [30, 30], 'readout_fcn_activation': 'relu', 'self_connection_type': 'nequip', 'interaction_type': 'nequip', '_normalize_sph': True}\n",
      "{'irreps_manual': False, 'channel': 32, 'lmax': 1, 'lmax_edge': -1, 'lmax_node': -1, 'is_parity': True, 'radial_basis': {'radial_basis_name': 'bessel'}, 'cutoff_function': {'cutoff_function_name': 'poly_cut'}, 'act_radial': 'silu', 'cutoff': 4, 'weight_nn_hidden_neurons': [64, 64], 'num_convolution_layer': 3, 'act_scalar': {'e': 'silu', 'o': 'tanh'}, 'act_gate': {'e': 'silu', 'o': 'tanh'}, 'conv_denominator': 'avg_num_neigh', 'train_denominator': False, 'train_shift_scale': False, 'use_bias_in_linear': False, 'readout_as_fcn': False, 'readout_fcn_hidden_neurons': [30, 30], 'readout_fcn_activation': 'relu', 'self_connection_type': 'nequip', 'interaction_type': 'nequip', '_normalize_sph': True}\n",
      "{'irreps_manual': False, 'channel': 32, 'lmax': 1, 'lmax_edge': -1, 'lmax_node': -1, 'is_parity': True, 'radial_basis': {'radial_basis_name': 'bessel'}, 'cutoff_function': {'cutoff_function_name': 'XPLOR', 'cutoff_on': 3.5}, 'act_radial': 'silu', 'cutoff': 4, 'weight_nn_hidden_neurons': [64, 64], 'num_convolution_layer': 3, 'act_scalar': {'e': 'silu', 'o': 'tanh'}, 'act_gate': {'e': 'silu', 'o': 'tanh'}, 'conv_denominator': 'avg_num_neigh', 'train_denominator': False, 'train_shift_scale': False, 'use_bias_in_linear': False, 'readout_as_fcn': False, 'readout_fcn_hidden_neurons': [30, 30], 'readout_fcn_activation': 'relu', 'self_connection_type': 'nequip', 'interaction_type': 'nequip', '_normalize_sph': True}\n",
      "{'irreps_manual': False, 'channel': 32, 'lmax': 1, 'lmax_edge': -1, 'lmax_node': -1, 'is_parity': True, 'radial_basis': {'radial_basis_name': 'bessel'}, 'cutoff_function': {'cutoff_function_name': 'XPLOR', 'cutoff_on': 5.5}, 'act_radial': 'silu', 'cutoff': 6, 'weight_nn_hidden_neurons': [64, 64], 'num_convolution_layer': 3, 'act_scalar': {'e': 'silu', 'o': 'tanh'}, 'act_gate': {'e': 'silu', 'o': 'tanh'}, 'conv_denominator': 'avg_num_neigh', 'train_denominator': False, 'train_shift_scale': False, 'use_bias_in_linear': False, 'readout_as_fcn': False, 'readout_fcn_hidden_neurons': [30, 30], 'readout_fcn_activation': 'relu', 'self_connection_type': 'nequip', 'interaction_type': 'nequip', '_normalize_sph': True}\n"
     ]
    }
   ],
   "source": [
    "# make 2 edge_embedding layer!!\n",
    "import copy\n",
    "graph_6cut = AtomGraphData.from_numpy_dict(unlabeled_atoms_to_graph(atoms, 6.0))\n",
    "graph_4cut = AtomGraphData.from_numpy_dict(unlabeled_atoms_to_graph(atoms, 4.0))\n",
    "model_cfg1 = copy.deepcopy(DEFAULT_E3_EQUIVARIANT_MODEL_CONFIG)\n",
    "model_cfg2 = copy.deepcopy(DEFAULT_E3_EQUIVARIANT_MODEL_CONFIG)\n",
    "model_cfg3 = copy.deepcopy(DEFAULT_E3_EQUIVARIANT_MODEL_CONFIG)\n",
    "model_cfg4 = copy.deepcopy(DEFAULT_E3_EQUIVARIANT_MODEL_CONFIG)\n",
    "model_cfg1['cutoff_function'] = {'cutoff_function_name': 'poly_cut'}\n",
    "model_cfg1['cutoff'] = 6\n",
    "model_cfg2['cutoff_function'] = {'cutoff_function_name': 'poly_cut'}\n",
    "model_cfg2['cutoff'] = 4\n",
    "print(model_cfg1)\n",
    "print(model_cfg2)\n",
    "edge_embedding_layer_6cut = init_edge_embedding(model_cfg1)\n",
    "edge_embedding_layer_4cut = init_edge_embedding(model_cfg2)\n",
    "graph_6cut_from_6data_poly = edge_embedding_layer_6cut(copy.deepcopy(graph_6cut))\n",
    "graph_4cut_from_4data_poly = edge_embedding_layer_4cut(copy.deepcopy(graph_4cut))\n",
    "# how about mixed?\n",
    "graph_4cut_from_6data_poly = edge_embedding_layer_4cut(copy.deepcopy(graph_6cut))\n",
    "graph_6cut_from_4data_poly = edge_embedding_layer_6cut(copy.deepcopy(graph_4cut))\n",
    "\n",
    "# new edge_embedding layer!!\n",
    "model_cfg3['cutoff_function'] = {'cutoff_function_name': 'XPLOR', 'cutoff_on': 3.5}\n",
    "model_cfg3['cutoff'] = 4\n",
    "edge_embedding_layer_4cut_xplor = init_edge_embedding(model_cfg3)\n",
    "model_cfg4['cutoff_function'] = {'cutoff_function_name': 'XPLOR', 'cutoff_on': 5.5}\n",
    "model_cfg4['cutoff'] = 6\n",
    "edge_embedding_layer_6cut_xplor = init_edge_embedding(model_cfg4)\n",
    "print(model_cfg3)\n",
    "print(model_cfg4)\n",
    "\n",
    "graph_4cut_from_4data_xplor = edge_embedding_layer_4cut_xplor(copy.deepcopy(graph_4cut))\n",
    "graph_6cut_from_6data_xplor = edge_embedding_layer_6cut_xplor(copy.deepcopy(graph_4cut))\n",
    "graph_4cut_from_6data_xplor = edge_embedding_layer_4cut_xplor(copy.deepcopy(graph_4cut))\n",
    "graph_6cut_from_4data_xplor = edge_embedding_layer_6cut_xplor(copy.deepcopy(graph_4cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_embedding\n",
      "4cut vs 6cut from 4cut data: False\n",
      "6cut vs 4cut from 6cut data: False\n",
      "-----------------------------------\n",
      "edge_length\n",
      "4cut vs 6cut from 4cut data: True\n",
      "6cut vs 4cut from 6cut data: True\n",
      "-----------------------------------\n",
      "edge_attr\n",
      "4cut vs 6cut from 4cut data: True\n",
      "6cut vs 4cut from 6cut data: True\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "check_key = [KEY.EDGE_EMBEDDING, KEY.EDGE_LENGTH, KEY.EDGE_ATTR]\n",
    "for key in check_key:\n",
    "    # check just 4cut vs 6cut from 4cut data\n",
    "    print(f'{key}')\n",
    "    print(f'4cut vs 6cut from 4cut data: {torch.equal(graph_4cut_from_4data_poly[key], graph_6cut_from_4data_poly[key])}')\n",
    "    # 6cut vs 4cut from 6cut data\n",
    "    print(f'6cut vs 4cut from 6cut data: {torch.equal(graph_6cut_from_6data_poly[key], graph_4cut_from_6data_poly[key])}')\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_embedding\n",
      "4cut vs 4cut: False\n",
      "6cut vs 6cut: False\n",
      "4cut from 6: False\n",
      "6cut from 4: False\n",
      "edge_length\n",
      "4cut vs 4cut: True\n",
      "6cut vs 6cut: False\n",
      "4cut from 6: False\n",
      "6cut from 4: True\n",
      "edge_attr\n",
      "4cut vs 4cut: True\n",
      "6cut vs 6cut: False\n",
      "4cut from 6: False\n",
      "6cut from 4: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "check_key = [KEY.EDGE_EMBEDDING, KEY.EDGE_LENGTH, KEY.EDGE_ATTR]\n",
    "for key in check_key:\n",
    "    # check just 4cut vs 6cut from 4cut data\n",
    "    print(f'{key}')\n",
    "    print(f'4cut vs 4cut: {torch.equal(graph_4cut_from_4data_poly[key], graph_4cut_from_4data_xplor[key])}')\n",
    "    # 6cut vs 4cut from 6cut data\n",
    "    print(f'6cut vs 6cut: {torch.equal(graph_6cut_from_6data_poly[key], graph_6cut_from_6data_xplor[key])}')\n",
    "    print(f'4cut from 6: {torch.equal(graph_4cut_from_6data_poly[key], graph_4cut_from_6data_xplor[key])}')\n",
    "    print(f'6cut from 4: {torch.equal(graph_6cut_from_4data_poly[key], graph_6cut_from_4data_xplor[key])}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does filtering work??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# compare 4cut 4data and 4cut 6data\n",
    "edge_embed_4cut_4data = graph_4cut_from_4data_poly[KEY.EDGE_EMBEDDING].detach().numpy()\n",
    "edge_embed_4cut_6data = graph_4cut_from_6data_poly[KEY.EDGE_EMBEDDING].detach().numpy()\n",
    "edge_length_4cut_4data = graph_4cut_from_4data_poly[KEY.EDGE_LENGTH].numpy()\n",
    "edge_length_4cut_6data = graph_4cut_from_6data_poly[KEY.EDGE_LENGTH].numpy()\n",
    "edge_attr_4cut_4data = graph_4cut_from_4data_poly[KEY.EDGE_ATTR].numpy()\n",
    "edge_attr_4cut_6data = graph_4cut_from_6data_poly[KEY.EDGE_ATTR].numpy()\n",
    "\n",
    "# filter edge_length < 4\n",
    "condition = edge_length_4cut_6data <= 4\n",
    "new_edge_length_4cut_6data = edge_length_4cut_6data[condition]\n",
    "new_edge_embed_4cut_6data = edge_embed_4cut_6data[condition]\n",
    "new_edge_attr_4cut_6data = edge_attr_4cut_6data[condition]\n",
    "\n",
    "# check if they are same\n",
    "sorted_indices_4cut_4data = np.lexsort(\n",
    "    (edge_embed_4cut_4data[:, 2], edge_embed_4cut_4data[:, 1], edge_embed_4cut_4data[:, 0])\n",
    ")\n",
    "sorted_indices_4cut_6data = np.lexsort(\n",
    "    (new_edge_embed_4cut_6data[:, 2], new_edge_embed_4cut_6data[:, 1], new_edge_embed_4cut_6data[:, 0])\n",
    ")\n",
    "print(np.allclose(edge_embed_4cut_4data[sorted_indices_4cut_4data], new_edge_embed_4cut_6data[sorted_indices_4cut_6data]))\n",
    "print(np.allclose(edge_length_4cut_4data[sorted_indices_4cut_4data], new_edge_length_4cut_6data[sorted_indices_4cut_6data]))\n",
    "print(np.allclose(edge_attr_4cut_4data[sorted_indices_4cut_4data], new_edge_attr_4cut_6data[sorted_indices_4cut_6data]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# compare 4cut 4data and 4cut 6data\n",
    "edge_embed_4cut_4data = graph_4cut_from_4data_xplor[KEY.EDGE_EMBEDDING].detach().numpy()\n",
    "edge_embed_4cut_6data = graph_4cut_from_6data_xplor[KEY.EDGE_EMBEDDING].detach().numpy()\n",
    "edge_length_4cut_4data = graph_4cut_from_4data_xplor[KEY.EDGE_LENGTH].numpy()\n",
    "edge_length_4cut_6data = graph_4cut_from_6data_xplor[KEY.EDGE_LENGTH].numpy()\n",
    "edge_attr_4cut_4data = graph_4cut_from_4data_xplor[KEY.EDGE_ATTR].numpy()\n",
    "edge_attr_4cut_6data = graph_4cut_from_6data_xplor[KEY.EDGE_ATTR].numpy()\n",
    "\n",
    "# filter edge_length < 4\n",
    "condition = edge_length_4cut_6data <= 4\n",
    "new_edge_length_4cut_6data = edge_length_4cut_6data[condition]\n",
    "new_edge_embed_4cut_6data = edge_embed_4cut_6data[condition]\n",
    "new_edge_attr_4cut_6data = edge_attr_4cut_6data[condition]\n",
    "\n",
    "# check if they are same\n",
    "sorted_indices_4cut_4data = np.lexsort(\n",
    "    (edge_embed_4cut_4data[:, 2], edge_embed_4cut_4data[:, 1], edge_embed_4cut_4data[:, 0])\n",
    ")\n",
    "sorted_indices_4cut_6data = np.lexsort(\n",
    "    (new_edge_embed_4cut_6data[:, 2], new_edge_embed_4cut_6data[:, 1], new_edge_embed_4cut_6data[:, 0])\n",
    ")\n",
    "print(np.allclose(edge_embed_4cut_4data[sorted_indices_4cut_4data], new_edge_embed_4cut_6data[sorted_indices_4cut_6data]))\n",
    "print(np.allclose(edge_length_4cut_4data[sorted_indices_4cut_4data], new_edge_length_4cut_6data[sorted_indices_4cut_6data]))\n",
    "print(np.allclose(edge_attr_4cut_4data[sorted_indices_4cut_4data], new_edge_attr_4cut_6data[sorted_indices_4cut_6data]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multicutoff model making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sevenn._keys as KEY\n",
    "import sevenn.util as util\n",
    "from sevenn.atom_graph_data import AtomGraphData\n",
    "from sevenn.nn.sequential import AtomGraphSequential\n",
    "from sevenn.train.dataload import unlabeled_atoms_to_graph\n",
    "from ase.io import read\n",
    "from sevenn.nn.edge_embedding import (\n",
    "    BesselBasis,\n",
    "    EdgeEmbedding,\n",
    "    PolynomialCutoff,\n",
    "    SphericalEncoding,\n",
    "    XPLORCutoff,\n",
    ")\n",
    "from sevenn._const import DEFAULT_E3_EQUIVARIANT_MODEL_CONFIG, model_defaults\n",
    "from sevenn.model_build import init_edge_embedding, build_E3_equivariant_model\n",
    "\n",
    "atoms = read('Mg4Ta8O24.cif')\n",
    "graph_6cut = AtomGraphData.from_numpy_dict(unlabeled_atoms_to_graph(atoms, 6.0))\n",
    "graph_4cut = AtomGraphData.from_numpy_dict(unlabeled_atoms_to_graph(atoms, 4.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "model_cfg_multi = copy.deepcopy(DEFAULT_E3_EQUIVARIANT_MODEL_CONFIG)\n",
    "\n",
    "model_cfg_multi['cutoff_function'] = {'cutoff_function_name': 'poly_cut'}\n",
    "model_cfg_multi['cutoff'] = 5\n",
    "model_cfg_multi['multi_cutoff'] = [5, 5, 4, 5, 5]\n",
    "\n",
    "\n",
    "multi_edge_embedding_layer_6cut = init_edge_embedding(model_cfg_multi)\n",
    "\n",
    "multi_graph_6cut_from_6data_poly = multi_edge_embedding_layer_6cut(copy.deepcopy(graph_6cut))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AtomGraphData(\n",
      "  x=[36],\n",
      "  edge_index=[2, 2910],\n",
      "  pos=[36, 3],\n",
      "  node_attr=[36],\n",
      "  atomic_numbers=[36],\n",
      "  edge_vec=[2910, 3],\n",
      "  cell_lattice_vectors=[3, 3],\n",
      "  pbc_shift=[2910, 3],\n",
      "  cell_volume=410.892333984375,\n",
      "  num_atoms=36,\n",
      "  data_info={},\n",
      "  edge_length=[2910],\n",
      "  edge_embedding4=[818, 8],\n",
      "  edge_attr4=[818, 4],\n",
      "  edge_index4=[2, 818],\n",
      "  edge_embedding5=[1488, 8],\n",
      "  edge_attr5=[1488, 4],\n",
      "  edge_index5=[2, 1488]\n",
      ")\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(multi_graph_6cut_from_6data_poly)\n",
    "print(sys.getsizeof(multi_graph_6cut_from_6data_poly))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model build test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Tuple, Union\n",
    "import warnings\n",
    "def _patch_old_config(config: Dict[str, Any]):\n",
    "    # Fixing my old mistakes\n",
    "    if config[KEY.CUTOFF_FUNCTION][KEY.CUTOFF_FUNCTION_NAME] == 'XPLOR':\n",
    "        config[KEY.CUTOFF_FUNCTION].pop('poly_cut_p_value', None)\n",
    "    if KEY.TRAIN_DENOMINTAOR not in config:\n",
    "        config[KEY.TRAIN_DENOMINTAOR] = config.pop('train_avg_num_neigh', False)\n",
    "    _opt = config.pop('optimize_by_reduce', None)\n",
    "    if _opt is False:\n",
    "        raise ValueError(\n",
    "            'This checkpoint(optimize_by_reduce: False) is no longer supported'\n",
    "        )\n",
    "    if KEY.CONV_DENOMINATOR not in config:\n",
    "        config[KEY.CONV_DENOMINATOR] = 0.0\n",
    "    if KEY._NORMALIZE_SPH not in config:\n",
    "        config[KEY._NORMALIZE_SPH] = False\n",
    "        # Warn this in the docs, not here for SevenNet-0 (22May2024)\n",
    "    return config\n",
    "\n",
    "def _map_old_model(old_model_state_dict):\n",
    "    \"\"\"\n",
    "    For compatibility with old namings (before 'correct' branch merged 2404XX)\n",
    "    Map old model's module names to new model's module names\n",
    "    \"\"\"\n",
    "    _old_module_name_mapping = {\n",
    "        'EdgeEmbedding': 'edge_embedding',\n",
    "        'reducing nn input to hidden': 'reduce_input_to_hidden',\n",
    "        'reducing nn hidden to energy': 'reduce_hidden_to_energy',\n",
    "        'rescale atomic energy': 'rescale_atomic_energy',\n",
    "    }\n",
    "    for i in range(10):\n",
    "        _old_module_name_mapping[f'{i} self connection intro'] = (\n",
    "            f'{i}_self_connection_intro'\n",
    "        )\n",
    "        _old_module_name_mapping[f'{i} convolution'] = f'{i}_convolution'\n",
    "        _old_module_name_mapping[f'{i} self interaction 2'] = (\n",
    "            f'{i}_self_interaction_2'\n",
    "        )\n",
    "        _old_module_name_mapping[f'{i} equivariant gate'] = f'{i}_equivariant_gate'\n",
    "\n",
    "    new_model_state_dict = {}\n",
    "    for k, v in old_model_state_dict.items():\n",
    "        key_name = k.split('.')[0]\n",
    "        follower = '.'.join(k.split('.')[1:])\n",
    "        if 'denumerator' in follower:\n",
    "            follower = follower.replace('denumerator', 'denominator')\n",
    "        if key_name in _old_module_name_mapping:\n",
    "            new_key_name = _old_module_name_mapping[key_name] + '.' + follower\n",
    "            new_model_state_dict[new_key_name] = v\n",
    "        else:\n",
    "            new_model_state_dict[k] = v\n",
    "    return new_model_state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi cutoff list: [5, 5, 4, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "# load weight manually\n",
    "checkpoint = util.pretrained_name_to_path('7net-0')\n",
    "check_point_loaded = torch.load(checkpoint, map_location='cpu', weights_only=False)\n",
    "model_state_dict = check_point_loaded['model_state_dict']\n",
    "config = check_point_loaded['config']\n",
    "defaults = {**model_defaults(config)}\n",
    "config = _patch_old_config(config)\n",
    "\n",
    "for k, v in defaults.items():\n",
    "    if k not in config:\n",
    "        warnings.warn(f'{k} not in config, using default value {v}', UserWarning)\n",
    "        config[k] = v\n",
    "for k, v in config.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        config[k] = v.cpu()\n",
    "\n",
    "# multi cutoff model\n",
    "multi_cutoff_list = [5, 5, 4, 5, 5]\n",
    "print(f'multi cutoff list: {multi_cutoff_list}')\n",
    "# config['multi_cutoff'] = multi_cutoff_list\n",
    "model = build_E3_equivariant_model(config)\n",
    "\n",
    "missing, _ = model.load_state_dict(model_state_dict, strict=False)\n",
    "if len(missing) > 0:\n",
    "    updated = _map_old_model(model_state_dict)\n",
    "    missing, not_used = model.load_state_dict(updated, strict=False)\n",
    "    if len(not_used) > 0:\n",
    "        warnings.warn(f'Some keys are not used: {not_used}', UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mc\n",
      "Parameter containing:\n",
      "tensor([0.5079, 1.1099, 1.7265, 2.3767, 3.0392, 3.7201, 4.4142, 5.1186],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.2098, -2.5352, -1.1502,  ...,  3.7544,  1.4783, -0.2325],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('model mc')\n",
    "    print(model.edge_embedding.basis_functions[0].coeffs)\n",
    "    print(model.edge_embedding.basis_functions[1].coeffs)\n",
    "    print(model._modules['0_self_interaction_1'].linear.weight)\n",
    "except:\n",
    "    print(model.edge_embedding.basis_function.coeffs)\n",
    "    print(model._modules['0_self_interaction_1'].linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 1.7966,  0.3282,  0.6795,  ..., -0.2949, -0.0243, -0.6929],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model mc\n",
    "# Parameter containing:\n",
    "# tensor([0.7854, 1.5708, 2.3562, 3.1416, 3.9270, 4.7124, 5.4978, 6.2832],\n",
    "#        requires_grad=True)\n",
    "# Parameter containing:\n",
    "# tensor([0.6283, 1.2566, 1.8850, 2.5133, 3.1416, 3.7699, 4.3982, 5.0265],\n",
    "#        requires_grad=True)\n",
    "# Parameter containing:\n",
    "# tensor([-1.2098, -2.5352, -1.1502,  ...,  3.7544,  1.4783, -0.2325],\n",
    "#        requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
